---
title: "Reversal_Results"
author: "Sophie Paolizzi"
date: "5/6/2022"
output: html_document
---
### Hypotheses 

A. In a serial reversal task, there will be a relationship between more severe BPD symptoms (as indexed by the PAI-BOR) and relatively faster detection of contingency reversals, as indicated by fewer incorrect responses post-reversal. These learners will also be less likely to choose the same option consistently across the blocks. 
B.  In a serial reversal task, higher scores on the PSWQ will be associated with relatively slower detection of reversing reward contingencies; Participants with higher PSWQ scores will tend to be consistent in their choices and experience more errors (and less correct answers) in learning post-reversal. 

```{r setup, include=FALSE}
pacman::p_load(tidyverse, dplyr, sjPlot, readr, janitor, ggplot2,wesanderson, cowplot, flextable, plotly, emmeans, lme4, qualtRics, sjPlot, circular, pracma, cowplot, psych, lattice)
##### Load Data and setwd
ll = FALSE
if (ll == TRUE) {
  home_directory <- "/proj/mnhallqlab/users/sophie/ReversalTask/"
  data_dir <- file.path(paste0(home_directory, "data/"))
} else {
  home_directory <- "~/github_repos/ReversalTask/"
  data_dir <- file.path(paste0(home_directory, "Data/"))
}
load(file = paste0(data_dir,'base_effects_data.RData'))

data <- df %>% dplyr::filter(rt !=0) %>% dplyr::filter(!isResponseCorrect == 0) %>% filter(subject != 270470)

data$rt_log <- log(data$rt)
data$rt_inv<- -1/1000*(data$rt)
minfo<- list()
load("~/github_repos/Cannon_Task/Analysis/lmer/glmer_mods.Rdata")
data$ResponseCorrect_num <- data$ResponseCorrect_num %>% dplyr::recode("-1" = 0, "1" = 1)
data$trial_z <- scale(data$trial_number)
data$total_trial_z <- scale(data$total_trialnum)
data$prevRT_log <- lag(log(data$rt))
data$prevResponse<- as.factor(data$prevResponse)
data$prevFeedback <- as.factor(data$prevFeedback)
data$task_phase <- as.factor(data$task_phase)
```


### Base model
Start with the basics.... should be an effect of trial number based on tidy_markdown. 
```{r}
minfo[["mod0"]] <- c(fixed="Intercept", l2="Intercept/Subject")
mod0 <- glmer(ResponseCorrect_num ~ 1 + (1|subject), family = binomial, control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10, data = df)

minfo[["mod1"]] <- c(fixed="Total Trial", l2="Intercept/Subject")
mod1 <- glmer(ResponseCorrect_num ~  total_trialnum + (1|subject), data = df, family = binomial, control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10)
#note: trial_number is within-block (i.e., 1-40)
minfo[["mod1.1"]] <- c(fixed="block_trial_number, block number", l2="Intercept/Subject")
mod1.1 <- glmer(ResponseCorrect_num ~  trial_number + block_number + (1|subject), data = df, family = binomial, control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10); summary(mod1.1)
resids <- residuals(mod1.1)
fitted <- fitted(mod1.1)
plot(fitted, resids)
AIC(mod0, mod1, mod1.1)
```

### Rescale trials
Carry 2.1 forward, total_trial covers what we need best. Z-scoring within subject as well. 
```{r}
minfo[["mod2"]] <- c(fixed="block_trial_z, block number", l2="Intercept/Subject")
mod2 <- glmer(ResponseCorrect_num ~ trial_z + block_number + (1 |subject), data = df, family = binomial, control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10); summary(mod2)

minfo[["mod2.1"]] <- c(fixed="total_trial_z", l2="Intercept/Subject")
mod2.1 <- glmer(ResponseCorrect_num ~ total_trial_z + (1 |subject), data = df, family = binomial, control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10)

AIC(mod2,mod2.1)
```


### Add in RT
seems trial-wise RT is doing a little. 
```{r}
minfo[["mod3"]] <- c(fixed="total_trial_z, PrevRT", l2="Intercept/Subject")
mod3 <- glmer(ResponseCorrect_num ~ total_trial_z + rt_log + (1 |subject), data = df, family = binomial, control = glmerControl(optimizer = "bobyqa"))
AIC(mod2.1, mod3)
```

### Add in previous RT
We've got an effect here of previous RT; seems to be a clear winner. 
```{r}
minfo[["mod3.1"]] <- c(fixed="total_trial_z, PrevRT, RT", l2="Intercept/Subject")
mod3.1 <- glmer(ResponseCorrect_num ~ total_trial_z + prevRT_log + rt_log + (1 |subject), data = df, family = binomial, control = glmerControl(optimizer = "bobyqa"))
AIC(mod2.1, mod3.1)
```


### Task_phase
Some clear improvement! Good news for our hypotheses re: task phase shifts
```{r}
minfo[["mod4"]] <- c(fixed="total_trial_z, PrevRT, RT, task phase", l2="Intercept/Subject")
mod4 <- glmer(ResponseCorrect_num ~ total_trial_z + prevRT_log + rt_log + task_phase + (1 |subject), data = df, family = binomial, control = glmerControl(optimizer = "bobyqa"))
summary(mod4)
AIC(mod3.1, mod4)
```

### previous feedback (previous error, kind of)
A previous perceived error leads to choosing the wrong stimulus on the current trial. Seems like a basic win-stay lose-switch strategy, but ignoring the probabilistic part. 
```{r}
minfo[["mod5"]] <- c(fixed="total_trial_z, PrevRT, task phase, previous feedback", l2="Intercept/Subject")
mod5 <- glmer(ResponseCorrect_num ~ total_trial_z + prevRT_log + rt_log + task_phase + prevFeedback + (1 |subject), data = df, family = binomial, control = glmerControl(optimizer = "bobyqa"))
summary(mod5)
dependlab::render_flex_aictab(minfo=minfo, mod0, mod1, mod1.1, mod2, mod2.1, mod3, mod4, mod5) %>% autofit() 
```

### previous response (sort of a stickiness type deal?)
Clear winner in 6.1; Interaction between feedback and response. We starting to see some upward trends in collinearity we should watch out for. 
```{r}
minfo <- list()
minfo[["mod6"]] <- c(fixed="tot_trial_z, PrevRT, RT, phase, prevFeed, prevResp", l2="Intercept/Subject")
mod6 <- glmer(ResponseCorrect_num ~ total_trial_z + prevRT_log + rt_log + task_phase + prevFeedback + prevResponse + (1 |subject), data = df, family = binomial, control = glmerControl(optimizer = "bobyqa"))

minfo[["mod6.1"]] <- c(fixed="tot_trial_z, PrevRT, RT, phase, prevFeed*prevResp", l2="Intercept/Subject")
mod6.1 <- glmer(ResponseCorrect_num ~ total_trial_z + prevRT_log + rt_log + task_phase + prevFeedback*prevResponse + (1 |subject), data = df, family = binomial, control = glmerControl(optimizer = "bobyqa"))
AIC(mod5, mod6, mod6.1)
car::vif(mod6.1)
summary(mod6.1)
plot_model(mod6.1, type = "pred", terms = c("prevFeedback", "prevResponse"))
```

### Interaction with phase and feedback
We see some potential here for a phasexfeedback interaction, suggesting that previous feedback in the reversal block is slightly less salient. 
```{r}
minfo[["mod6.2"]] <- c(fixed="tot_trial_z, PrevRT, RT, phase*prevFeed, prevResp*prevFeed", l2="Intercept/Subject")
mod6.2 <- glmer(ResponseCorrect_num ~ total_trial_z + prevRT_log + rt_log  + task_phase + task_phase*prevFeedback + prevFeedback*prevResponse + (1 |subject), data = df, family = binomial, control = glmerControl(optimizer = "bobyqa"))
```

### 3-way interaction with phase, feedback, and response
Also seems clear we shouldn't hope for a 3-way interaction with task phase, previous feedback, and previous response, collinearity is intense.  

```{r}
#minfo[["mod6.3"]] <- c(fixed="tot_trial_z, PrevRT, RT, phase, phase*prevFeed, prevFeed*prevResp", l2="Intercept/Subject")
mod6.3 <- glmer(ResponseCorrect_num ~ total_trial_z + rt_log + prevRT_log + task_phase + task_phase*prevFeedback*prevResponse + (1 |subject), data = df, family = binomial, control = glmerControl(optimizer = "bobyqa")) #very collinear, probably not salvageable
```

### Decomposing 3-way interaction
Pretty close in fit to our previous model. Maybe makes sense to carry this forward for now.
```{r}
minfo[["mod6.4"]] <- c(fixed="tot_trial_z, PrevRT, RT, phase, , prevResp*phase, phase*prevFeed, prevFeed*prevResp", l2="Intercept/Subject")
mod6.4 <- glmer(ResponseCorrect_num ~ total_trial_z + prevRT_log + rt_log + task_phase*prevResponse + prevFeedback*task_phase + prevFeedback*prevResponse + (1 |subject), data = df, family = binomial, control = glmerControl(optimizer = "bobyqa"))

dependlab::render_flex_aictab(minfo=minfo, mod6, mod6.1, mod6.2, mod6.4) %>% autofit() 
```


### Attempt to understand 4-way categories: responseAndFeedbackCategory variable....
Before we officially move in, we do have a variable that has 4 levels, but it's not working the way I'd like; I don't know of a dummy code that lets me do a 4-way contrast... we should stick with 6 for now. We can definitely say the prevresponse*prevfeeback interaction is in: the others seem like they might have potential once we start playing with random effects. 
```{r}
mod7 <- glmer(ResponseCorrect_num ~ total_trial_z + prevRT_log + rt_log + responseAndFeedbackCategory*task_phase + responseAndFeedbackCategory + (1 |subject), data = df, family = binomial, control = glmerControl(optimizer = "bobyqa")) #she's a degenerate Hessian, not worth considering. 
```


### Key Random Effects

**Subject**. We are interested in within-subject variation, for sure. 
**Previous Response**. Clear "stickiness" effect of previous response - we want to know if this is heterogenous by subject
**Previous Feedback**. Clear impact of feedback on current choice - we want to know if this is heterogenous by subject
**Task Phase**. It is critical that we understand how the task phase manipulation palys into this. 

#### Basic Random Slopes
Seems there are worthwhile random slopes of task phase, previous response, and previous feedback. Curious whether a within-phase nesting structure makes more sense. 
```{r}
minfo[["mod8a"]] <- c(fixed="tot_trial_z, PrevRT, phase*prevFeed, prevFeed*prevResp", l2="Intercept + prevResp/Subject")
mod8a <- glmer(ResponseCorrect_num ~ total_trial_z + prevRT_log + rt_log + task_phase*prevResponse + prevFeedback*task_phase + prevFeedback*prevResponse + (1 + prevResponse |subject), data = data, family = binomial, control = glmerControl(optimizer = "bobyqa"))

minfo[["mod8b"]] <- c(fixed="tot_trial_z, PrevRT, phase*prevFeed, prevFeed*prevResp", l2="Intercept + prevResp+prevFeed/Subject")
mod8b <- glmer(ResponseCorrect_num ~ total_trial_z + prevRT_log + rt_log + task_phase*prevResponse + prevFeedback*task_phase + prevFeedback*prevResponse + (1 + prevResponse + prevFeedback |subject), data = data, family = binomial, control = glmerControl(optimizer = "bobyqa"))

minfo[["mod8c"]] <- c(fixed="tot_trial_z, PrevRT, phase*prevFeed, prevFeed*prevResp", l2="Intercept + prevResp+prevFeed+task_phase/Subject")
mod8c <- glmer(ResponseCorrect_num ~ total_trial_z + prevRT_log + rt_log + task_phase*prevResponse + prevFeedback*task_phase + prevFeedback*prevResponse + (1 + prevResponse + prevFeedback + task_phase |subject), data = data, family = binomial, control = glmerControl(optimizer = "bobyqa"))

summary(mod8c)
dependlab::render_flex_aictab(minfo=minfo, mod6, mod6.1, mod6.2, mod6.4, mod8a, mod8b, mod8c) %>% autofit() 
```

### Examine random effects structure
VERY clear correlations between random effects. Seems as though feedback and task phase are negatively correlated,  
```{r}
plot(ranef(mod8c))
```

```{r}
PrevResp_taskphase <- emmeans(mod8c, ~  prevResponse | task_phase, sigmaAdjust = c(TRUE, FALSE))
plot(PrevFeedback_taskphase)
```


```{r}
PrevFeedback_taskphase <- emmeans(mod8c, ~  prevFeedback | task_phase, sigmaAdjust = c(TRUE, FALSE))
plot(PrevResp_taskphase)
```

```{r}
prevResponse_Feedback <- emmeans(mod8c, ~   prevFeedback | prevResponse, sigmaAdjust = c(TRUE, FALSE))
plot(prevResponse_Feedback) #if you get correct 
```


```{r}
minfo[["mod8.1"]] <- c(fixed="tot_trial_z, PrevRT, phase*prevFeed, prevFeed*prevResp", l2="Intercept + Intercept+prevResp+prevFeed+task_phase/Subject, Intercept/Subject:task_phase")
mod8.1 <- glmer(ResponseCorrect_num ~ total_trial_z + prevRT_log + rt_log + task_phase*prevResponse + prevFeedback*task_phase + prevFeedback*prevResponse + (1 + prevResponse + prevFeedback + task_phase |subject) + (1 | subject:task_phase), data = data, family = binomial, control = glmerControl(optimizer = "bobyqa"))

VarCorr(mod8.1)
dependlab::render_flex_aictab(minfo=minfo, mod6, mod6.1, mod6.2, mod6.4, mod8a, mod8b, mod8c, mod8.1) %>% autofit() 
```

#### Grouping Structure including previous response
Curious if there's an interesting within-phase effect of previous response that varies by subject. Looks like this is generating large eigenvalues. 
```{r}
minfo[["mod8.2"]] <- c(fixed="tot_trial_z, PrevRT, phase*prevFeed, prevFeed*prevResp", l2="Intercept + Intercept+prevResp+prevFeed+task_phase/Subject, Intercept/Subject:task_phase, Intercept/Subject:prevResp")
mod8.2 <- glmer(ResponseCorrect_num ~ total_trial_z + prevRT_log + rt_log + task_phase*prevResponse + prevFeedback*task_phase + prevFeedback*prevResponse + (1 + prevFeedback + prevResponse + task_phase |subject) + (1 |prevResponse:task_phase), data = data, family = binomial, control = glmerControl(optimizer = "bobyqa"))
VarCorr(mod8.2)
dependlab::check_singularity(mod8.2)

minfo[["mod8.3"]] <- c(fixed="tot_trial_z, PrevRT, phase*prevFeed, prevFeed*prevResp", l2="Intercept + Intercept+prevResp+prevFeed+task_phase/Subject, Intercept/Subject:task_phase, Intercept/Subject:prevResp")
mod8.2 <- glmer(ResponseCorrect_num ~ total_trial_z + prevRT_log + rt_log + task_phase*prevResponse + prevFeedback*task_phase + prevFeedback*prevResponse + (1 + prevFeedback + prevResponse + task_phase |subject) + (1 |prevFeedback/task_phase), data = data, family = binomial, control = glmerControl(optimizer = "bobyqa"))
VarCorr(mod8.3)
dependlab::check_singularity(mod8.3)
```


#### Task Phase
```{r}
minfo[["mod1.1"]] <- c(fixed="total_trial_z, PrevRT, task phase, prevFeedback*task_phase, previous response*previous feedback", l2="Intercept, prevResponse, prevFeedback, task_phase/Subject")
mod1.1 <- glmer(ResponseCorrect_num ~ total_trial_z + prevRT_log + prevFeedback*task_phase + prevFeedback*prevResponse + (1  + prevResponse + prevFeedback + task_phase |subject), data = data, family = binomial, control = glmerControl(optimizer = "bobyqa"))
```

