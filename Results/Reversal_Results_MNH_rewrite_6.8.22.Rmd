---
title: "Reversal_Results"
author: "Sophie Paolizzi"
date: "5/6/2022"
output: html_document
---

#### Michael Feedback 6.08.22
1. Have you coded a variable for trial number since reversal? I would probably code this, and -100/this to capture how accuracy scales with trials since the reversal happened. That’s close to your stated hypothesis about sensitivity to reversal.
 - Done, added reversal sensitivty variable

Is previous response the identity of the previous response (like L/R or some other factor) or is it whether the previous response was correct (basically a lagged copy of the DV)?
If it’s the lagged copy, then this is capturing good behavior (choosing good things), but may not capture a preference for a given stimulus (that has a certain identity). Is that how you’re thinking about it?


I am thinking that the current setup of the models is probably capturing a lot of the key variance, but in ways that are hard to interpret and lead to challenges in the ranef corrs. I would consider running models that use stimulus identity as the DV or maybe even use stay/switch as 1/0. Could you send me your data.frame? I could probably prototype a couple of thigns for comparison, even if ultimately my hunch proves not to be useful

To your specific questions, I think the 3-way interaction reflects that previous choice outcome, not identity is in the interaction, so you get a lot of collinearity when people make repeated, good choices.

And that probably spills over into the ranef structure, which is too correlated to be entirely trustworthy.





11:24
I’m generally thinking of models that are closer to:
glmer(stim_choice ~ prior_A * prior_reward * task_phase + (1 | subject))





11:26
But I think you should be able to arrive at the same conclusions either way. This is very parallel to the (H)DDM consideratoin of stimulus versus accuracy coding. If you wanted to stay with accuracy coding, I think it would be:
glmer(choose_best ~ switch * prior_reward  * task_phase + (1|subject))

And with the trial regressor, it’s more like
glmer(choose_best ~ switch * prior_reward  * task_phase * stationary_trial + (1|subject))

where that stationary trial is the trial number since either beginning of block (acquisitoin) or post-reversal

Finally, we’ve approached these kinds of analyses before in terms of stay/switch as outcome (as mentioned above). I think this would be:
glmer(stay ~ prior_stay * prior_reward * task_phase * stationary_trial + (1|subject))


### Markdown Purpose and Content

This markdown follows the model selection procedure for the reversal task from the base model through the random effects structure. 

### Variables at Play
**ResponseCorrect_num**. Outcome variable: whether participants selected the outcome with a higher probabilistic change of accuracy.

**prevRT_log**. Reaction time in previous trial. 

**rt_log**. Reaction time of current trial. 

**block_number**. block number (1-5) of the task. 

**trial**. Within-trial block number.

**Total-trial**. number of trials across blocks in the task.

**Task Phase**. Reversal vs. Acquisition.

**Previous Response**. The response participants selected on the previous trial. 

**Previous Feedback**. Feedback recieved from the previous trial - importantly, this is probabilistic."Correct" feedback means participants were told they were correct, where "incorrect" feedback means participants were told they were incorrect. 

**ResponseandFeedbackCategory**. There are 4 possible outcomes combining previous response and previous feedback on any given trial. A participant could respond correctly and receive congruent feedback (CRCF; correct resp, feedback = "correct"); they could response incorrectly and receieve congruent feedback (IRCF; incorrect resp, feedback = "correct"); they could respond correctly and recieve incongruent feedback (CRIF; correct resp, feedback = "incorrect"); or they could respond incorrectly and recieve incorrect feedback (IRIF; incorrect resp, feedback = "correct"). 

### Hypotheses 
As a reminder, here are the hypotheses at play:

A. In a serial reversal task, there will be a relationship between heightened BPD symptoms (as indexed by the PAI-BOR) and relatively faster detection of contingency reversals, as indicated by fewer incorrect responses post-reversal. These learners will also be less likely to choose the same option consistently across the blocks. 
B.  In a serial reversal task, higher scores on the PSWQ will be associated with relatively slower detection of reversing reward contingencies; Participants with higher PSWQ scores will tend to be consistent in their choices and experience more errors (and less correct answers) in learning post-reversal. 

```{r setup, include=FALSE}
pacman::p_load(tidyverse, dplyr, sjPlot, readr, janitor, ggplot2,wesanderson, cowplot, flextable, plotly, emmeans, lme4, qualtRics, sjPlot, circular, pracma, cowplot, psych, lattice)
##### Load Data and setwd
ll = FALSE
if (ll == TRUE) {
  home_directory <- "/proj/mnhallqlab/users/sophie/ReversalTask/"
  data_dir <- file.path(paste0(home_directory, "data/"))
} else {
  home_directory <- "~/github_repos/ReversalTask/"
  data_dir <- file.path(paste0(home_directory, "Data/"))
}
load(file = paste0(data_dir,'base_effects_data.RData'))

data <- df %>% dplyr::filter(rt !=0) %>% dplyr::filter(!isResponseCorrect == 0) %>% filter(subject != 270470)

data$rt_log <- log(data$rt)
data$rt_inv<- -1/1000*(data$rt)
minfo<- list()
load("~/github_repos/Cannon_Task/Analysis/lmer/glmer_mods.Rdata")
data$ResponseCorrect_num <- data$ResponseCorrect_num %>% dplyr::recode("-1" = 0, "1" = 1)
data$prevResponse <- lag(data$Response) #last update
data$trial_z <- scale(data$trial_number)
data$total_trial_z <- scale(data$total_trialnum)
data$prevRT_log <- lag(log(data$rt))
data$prevResponse<- as.factor(data$prevResponse)
data$prevFeedback <- as.factor(data$prevFeedback)
data$task_phase <- as.factor(data$task_phase)
data$stim_choice <- ifelse(data$task_phase == "Acquisiton" & data$ResponseCorrect == 1, "Acq_stim", "tmp")
data$stim_choice <- ifelse(data$task_phase == "Reversal" & data$ResponseCorrect == 1, "Rev_stim", data$stim_choice)
data$stim_choice <- ifelse(data$task_phase == "Reversal" & data$ResponseCorrect == 0, "Acq_stim", data$stim_choice)
data$stim_choice <- ifelse(data$task_phase == "Acquisiton" & data$ResponseCorrect == 0, "Rev_stim", data$stim_choice)
data$stim_choice <- as.factor(data$stim_choice)
data$stim_choice <- relevel(data$stim_choice, ref = "Acq_stim")
data$prev_choice <- lag(data$stim_choice)
data$phase_trialnum_z <- scale(data$phase_trialnum)
data$since_reversal = scale(-100/data$phase_trialnum)

```






### Base model


### Adding in standard trial-level covariates; Trial
Adding in Michael's edits and beginning analysis from a stimulus_choice perspective; starting with trial; I compared total_trial_z, or trial number across the full task and all blocks, trial_z which is the scaled, within-block trial number, and the within-phase scaled trial number
```{r}
minfo[["mod0"]] <- c(fixed="within-block trial number", l2="Intercept/Subject")
mod0 <- glmer(stim_choice ~ trial_z + (1 | subject), family = binomial, control = glmerControl(optimizer = "bobyqa"), nAGQ = 10, data = data)

minfo[["mod0.1"]] <- c(fixed="Total trial number", l2="Intercept/Subject")
mod0.1 <- glmer(stim_choice ~ total_trial_z + (1 | subject), family = binomial, control = glmerControl(optimizer = "bobyqa"), nAGQ = 10, data = data)

minfo[["mod0.2"]] <- c(fixed="Phase-level Trial", l2="Intercept/Subject")
mod0.2 <- glmer(stim_choice ~ phase_trialnum_z + (1 | subject), family = binomial, control = glmerControl(optimizer = "bobyqa"), nAGQ = 10, data = data)


resids <- residuals(mod0)
fitted <- fitted(mod0)
plot(fitted, resids)
AIC(mod0, mod0.1, mod0.2)
summary(mod0)
```

Seems like total trial still wins out - carry forward. 

### Adding in standard trial-level covariates; RT
Adding in the trial RT to the upcoming models - doesn't seem to do much yet but would be interested to see if it comes out later. Leaving it for now. 
```{r}
minfo[["mod1"]] <- c(fixed="Trial, RT", l2="Intercept/Subject")
mod1 <- glmer(stim_choice ~ total_trial_z + rt_log + (1 | subject), family = binomial, control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10, data = data)
summary(mod1)

minfo[["mod1.1"]] <- c(fixed="Trial, RT, prevRT", l2="Intercept/Subject")
mod1.1 <- glmer(stim_choice ~ total_trial_z + rt_log + prevRT_log + (1 | subject), family = binomial, control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10, data = data)
summary(mod1.1)
AIC(mod0.1, mod1, mod1.1)
car::vif(mod1.1)
```


### Adding in standard trial-level covariates; Task phase
Adding in task block, huge improvement in AIC. 
```{r}
minfo[["mod2"]] <- c(fixed="Trial, RT, Phase", l2="Intercept/Subject")
mod2 <- glmer(stim_choice ~ total_trial_z + rt_log + prevRT_log + task_phase + (1 | subject), family = binomial, control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10, data = data)

AIC(mod2, mod1)

```

### Adding in previous choice
Adding in previous choice,  another huge improvement in AIC. These seem to wash out any high-level trial and RT effects that might exist. I reverted to phase_trialnum here and seem to be getting more traction with that. 
```{r}
minfo[["mod3"]] <- c(fixed="Trial, RT, Phase, Previous Choice", l2="Intercept/Subject")
mod3 <- glmer(stim_choice ~ prev_choice + total_trial_z + rt_log + prevRT_log + task_phase + (1 | subject), family = binomial, control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10, data = data)

minfo[["mod3.1"]] <- c(fixed="Trial, RT, Phase, Previous Choice", l2="Intercept/Subject")
mod3.1 <- glmer(stim_choice ~ prev_choice + phase_trialnum_z + rt_log + prevRT_log + task_phase + (1 | subject), family = binomial, control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10, data = data)

AIC(mod2, mod3, mod3.1)
summary(mod3.1)
car::vif(mod3.1)
```
So far, what I'm understanding is that stim choice and block are in fact related, such that people are more likely to choose the Acquisition stim in the acquisition block, and the reversal stim in the reversal block. Additionally, it seems people are slightly more likely to choose the Acquisition stimulus earlier in learning, compared to the reversal stimulus. 
```{r}
histogram(~stim_choice | task_phase, data = data)
ggplot(data, aes(x = trial_z, y = task_phase, color = stim_choice)) +  geom_point() + geom_jitter()
```


### Since Reversal
Some clear improvement! Good news for our hypotheses re: task phase shifts
```{r}
minfo[["mod4"]] <- c(fixed="Trial, RT, Phase, Previous Choice", l2="Intercept/Subject")
mod4 <- glmer(stim_choice ~ prev_choice + phase_trialnum_z + since_reversal + task_phase + (1 | subject), family = binomial, control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10, data = data)
summary(mod4)
car::vif(mod4)
AIC(mod3.1, mod4)
plot_model(mod4)
```
### previous_reward
previous feedback
```{r}
minfo[["mod5"]] <- c(fixed="Trial, RT, Phase, Previous Choice, trials since reversal", l2="Intercept/Subject")
mod5 <- glmer(stim_choice ~ prev_choice + task_phase + prevFeedback + phase_trialnum_z + rt_log + prevRT_log + since_reversal + (1 | subject), family = binomial, control=glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e4)),
    nAGQ = 10, data = data)
summary(mod5)
car::vif(mod5)
AIC(mod4, mod5)
```

### Investigating interactions: previous choice*task phase
this should give us a sense if people are generally "stickier" after reversals, or have a harder time adjusting to the new contingency. 
```{r}
minfo[["mod6"]] <- c(fixed="Trial, RT, Phase, Previous Choice, previous reward, trials since reversal", l2="Intercept/Subject", ixns="PhasexPrevious Choice")
mod6 <- glmer(stim_choice ~ prev_choice*task_phase + prevFeedback + phase_trialnum_z + rt_log + prevRT_log + since_reversal + (1 | subject), family = binomial, control=glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e4)),
    nAGQ = 10, data = data)
summary(mod6)
car::vif(mod6)
AIC(mod5, mod6)
plot_model(mod6, type = "pred", terms = c("prev_choice", "task_phase"))
```
### Investigating interactions: previous choice*task phase
```{r}
minfo[["mod7"]] <- c(fixed="Trial, RT, Phase, Previous Choice, trials since reversal", l2="Intercept/Subject")
mod7 <- glmer(stim_choice ~ prev_choice*task_phase+ task_phase*prevFeedback + rt_log + prevRT_log + phase_trialnum_z + since_reversal + (1 | subject), family = binomial, control=glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e4)),
    nAGQ = 10, data = data)
summary(mod7)
car::vif(mod7)
AIC(mod6, mod7)
plot_model(mod7, type = "pred", terms = c("task_phase", "prevFeedback"))
```

### Investigating interactions: previous choice*previous feedback

huge AIC improvement, defintely worth adding in. 
```{r}
minfo[["mod8"]] <- c(fixed="Trial, RT, Phase, Previous Choice, trials since reversal", l2="Intercept/Subject")
mod8 <- glmer(stim_choice ~ prev_choice*task_phase + task_phase*prevFeedback+ prev_choice*prevFeedback + rt_log + prevRT_log + phase_trialnum_z + since_reversal + (1 | subject), family = binomial, control=glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e4)),
    nAGQ = 10, data = data)
summary(mod8)
car::vif(mod8)
AIC(mod7, mod8)
plot_model(mod8, type = "pred", terms = c("task_phase", "prevFeedback"))
plot_model(mod8, type = "pred", terms = c("task_phase", "prev_choice"))
```
### Investigating interactions: previous choice*previous feedback

huge AIC improvement, defintely worth adding in. 
```{r}
minfo[["mod9"]] <- c(fixed="Trial, RT, Phase, Previous Choice, trials since reversal", l2="Intercept/Subject")
mod9 <- glmer(stim_choice ~ prev_choice*task_phase*prevFeedback+ prev_choice*prevFeedback + rt_log + prevRT_log + phase_trialnum_z + since_reversal + (1 | subject), family = binomial, control=glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e4)),
    nAGQ = 10, data = data)
summary(mod9)
car::vif(mod9)
AIC(mod8, mod9)
plot_model(mod8, type = "pred", terms = c("task_phase", "prevFeedback", "prev_choice"))
```



